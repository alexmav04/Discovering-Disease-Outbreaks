{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9e102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import re\n",
    "import json\n",
    "\n",
    "with open(\"./data/headlines.txt\", encoding=\"utf-8\") as file:\n",
    "    data = [headline.strip() for headline in file]\n",
    "data = [unidecode.unidecode(headline) for headline in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e5882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc1 = geonamescache.GeonamesCache()\n",
    "countries = [country[\"name\"] for country in gc1.get_countries().values()]\n",
    "cities = [city[\"name\"] for city in gc1.get_cities().values()]\n",
    "\n",
    "country_accent_mapping = {\n",
    "    unidecode.unidecode(country): country for country in countries\n",
    "}\n",
    "city_accent_mapping = {\n",
    "    unidecode.unidecode(city): city for city in cities\n",
    "}\n",
    "\n",
    "unaccented_cities = list(city_accent_mapping.keys())\n",
    "unaccented_countries = list(country_accent_mapping.keys())\n",
    "\n",
    "# sort cities and countries by length\n",
    "unaccented_cities = sorted(unaccented_cities, key=lambda x: len(x), reverse=True)\n",
    "unaccented_countries = sorted(unaccented_countries, key=lambda x: len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26fdc700",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_reg = r\"\\b|\\b\".join(unaccented_countries)\n",
    "city_reg = r'\\b|\\b'.join(unaccented_cities)\n",
    "\n",
    "## Find the citys or countrys in a text headline.\n",
    "def find_in_headline(headline):\n",
    "    country_match = re.search(country_reg, headline)\n",
    "    city_match = re.search(city_reg, headline)\n",
    "    countries = None if not country_match else country_match.group(0)\n",
    "    cities = None if not city_match else city_match.group(0)\n",
    "    return dict(headline=headline, countries=countries, cities=cities)\n",
    "\n",
    "## apply to all headlines\n",
    "headline_countries_cities = [\n",
    "    find_in_headline(headline) for headline in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7df38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"./data/headline_countries_cities.json\"\n",
    "with open(save_file, \"w\") as file:\n",
    "    file.write(json.dumps(headline_countries_cities))\n",
    "    \n",
    "with open(\"./data/country_accent_mapping.json\", \"w\") as file:\n",
    "    file.write(json.dumps(country_accent_mapping))    \n",
    "    \n",
    "with open(\"./data/city_accent_mapping.json\", \"w\") as file:\n",
    "    file.write(json.dumps(city_accent_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d8ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDO",
   "language": "python",
   "name": "discovering-disease-outbreaks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
